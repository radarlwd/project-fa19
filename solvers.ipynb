{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import student_utils\n",
    "import utils\n",
    "import solver\n",
    "import os\n",
    "import output_validator\n",
    "from queue import PriorityQueue\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building outputs from all algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best output for each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_outputs(pickle_dir):\n",
    "    pfiles = get_files_with_extension(pickle_dir, 'p')\n",
    "    dic = {}\n",
    "    meta_dic = {}\n",
    "    for pf in pfiles:\n",
    "        pobj = load_obj(pf)\n",
    "        for item in pobj:\n",
    "            # key=<./path/to/input_file>.in, value=(<./path/to/output_file.out>, cost)\n",
    "            input_file = item[0]\n",
    "            output_file = item[1]\n",
    "            cost = item[2][0]\n",
    "            if input_file in dic:\n",
    "                dic[input_file].append((output_file, cost))\n",
    "            else:\n",
    "                dic[input_file] = [(output_file, cost)]\n",
    "    if not os.path.isdir('final/outputs'):\n",
    "        os.mkdir('final')\n",
    "        os.mkdir('final/outputs')\n",
    "    for lst in dic.values():\n",
    "        best_output, best_cost = min(lst, key=lambda x: x[1])\n",
    "        os.system('cp ' + best_output + ' final/outputs/')\n",
    "        meta_dic[best_output] = best_cost\n",
    "    save_obj(meta_dic, 'final/meta.p')\n",
    "    write_data_to_file('final/meta.txt', meta_dic.items(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_outputs('pickle_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rao drives every TA home: this is a TSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    graph1, msg1 = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    path = []\n",
    "    drop_offs = {}\n",
    "    current_idx = start_idx\n",
    "    while homes_idx:\n",
    "        lst_dist = [(h_idx, nx.shortest_path_length(graph1, current_idx, h_idx, 'weight')) for h_idx in homes_idx]\n",
    "        idx, _ = min(lst_dist, key=lambda x: x[1])\n",
    "        shortest_path = nx.shortest_path(graph1, current_idx, idx, 'weight')\n",
    "        shortest_path.pop()\n",
    "        path.extend(shortest_path)\n",
    "        drop_offs[idx] = [idx]\n",
    "        current_idx = idx\n",
    "        homes_idx.remove(idx)\n",
    "    last_shortest_path = nx.shortest_path(graph1, current_idx, start_idx, 'weight')\n",
    "    path.extend(last_shortest_path)\n",
    "    return path, drop_offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "data = read_file('test_inputs/27_50.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "nn_solve(lst_loc, lst_house, start_loc, adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Algorithm with Different First Node After Starting Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_of_solution_no_print(G, car_cycle, dropoff_mapping):\n",
    "    cost = 0\n",
    "    dropoffs = dropoff_mapping.keys()\n",
    "    if not is_valid_walk(G, car_cycle):\n",
    "        print('This is not a valid walk for the given graph.\\n')\n",
    "        sys.exit()\n",
    "\n",
    "    if not car_cycle[0] == car_cycle[-1]:\n",
    "        print('The start and end vertices are not the same.\\n')\n",
    "        sys.exit()\n",
    "    if cost != 'infinite':\n",
    "        if len(car_cycle) == 1:\n",
    "            car_cycle = []\n",
    "        else:\n",
    "            car_cycle = get_edges_from_path(car_cycle[:-1]) + [(car_cycle[-2], car_cycle[-1])]\n",
    "        if len(car_cycle) != 1:\n",
    "            driving_cost = sum([G.edges[e]['weight'] for e in car_cycle]) * 2 / 3\n",
    "        else:\n",
    "            driving_cost = 0\n",
    "        walking_cost = 0\n",
    "        shortest = dict(nx.floyd_warshall(G))\n",
    "\n",
    "        for drop_location in dropoffs:\n",
    "            for house in dropoff_mapping[drop_location]:\n",
    "                walking_cost += shortest[drop_location][house]\n",
    "        cost = driving_cost + walking_cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn2_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    graph1, msg1 = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    start_shortest_paths = nx.shortest_path(graph1, start_idx, target=None, weight='weight')\n",
    "    minimum = float('inf')\n",
    "    final_path = []\n",
    "    final_dropoffs = {}\n",
    "    for h in homes_idx:\n",
    "        homes_copy = homes_idx.copy()\n",
    "        path = []\n",
    "        path.extend(start_shortest_paths[h])\n",
    "        path.pop()\n",
    "        drop_offs = {}\n",
    "        if start_idx in homes_copy:\n",
    "            drop_offs[start_idx] = [start_idx]\n",
    "            homes_copy.remove(start_idx)\n",
    "        current_idx = h\n",
    "        while homes_copy:\n",
    "            lst_dist = []\n",
    "            shortest_path_length = nx.shortest_path_length(graph1, current_idx, target=None, weight='weight')\n",
    "            for h in homes_copy:\n",
    "                lst_dist.append((h, shortest_path_length[h]))\n",
    "            idx, _ = min(lst_dist, key=lambda x: x[1])\n",
    "            shortest_path = nx.shortest_path(graph1, current_idx, idx, 'weight')\n",
    "            shortest_path.pop()\n",
    "            path.extend(shortest_path)\n",
    "            drop_offs[idx] = [idx]\n",
    "            current_idx = idx\n",
    "            homes_copy.remove(idx)\n",
    "        last_shortest_path = nx.shortest_path(graph1, current_idx, start_idx, 'weight')\n",
    "        path.extend(last_shortest_path)\n",
    "        cost = cost_of_solution_no_print(graph1, path, drop_offs)\n",
    "        if cost < minimum:\n",
    "            final_path = path\n",
    "            final_dropoffs = drop_offs\n",
    "    return final_path, final_dropoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('test_inputs/27_50.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "nn2_solve(lst_loc, lst_house, start_loc, adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Approximation using MST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the MST is connected then we can perform DFS and construct the path.\n",
    "- If the MST is not connected then we need to connect all homes by finding shortest paths between them.\n",
    "- To get the final path we look at each path in the list and check in the original graph, if there is an edge then we do nothing, but if it does not have an edge then we replace it with the shortest path between those nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_homes(graph, nodes):\n",
    "    newgraph = nx.Graph()\n",
    "    newgraph.add_nodes_from(nodes)\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            w = nx.shortest_path_length(graph, nodes[i], nodes[j], 'weight')\n",
    "            newgraph.add_edge(nodes[i], nodes[j], weight=w)\n",
    "    return newgraph\n",
    "    \n",
    "def mst_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    nodes = homes_idx + [start_idx]\n",
    "    graph, msg = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    newgraph = graph.subgraph(nodes)\n",
    "    if not nx.is_connected(newgraph):\n",
    "        newgraph = connect_homes(graph, nodes)\n",
    "    mst = nx.minimum_spanning_tree(newgraph, 'weight')\n",
    "    dfs = list(nx.dfs_edges(mst, start_idx))\n",
    "    path = [start_idx]\n",
    "    drop_offs = {}\n",
    "    if start_idx in homes_idx:\n",
    "        drop_offs[start_idx] = [start_idx]\n",
    "    current_idx = -1\n",
    "    while dfs:\n",
    "        edge = dfs.pop(0)\n",
    "        current_idx = edge[1]\n",
    "        if current_idx not in path:\n",
    "            path.append(current_idx)\n",
    "            drop_offs[current_idx] = [current_idx]\n",
    "    final_path = [path[0]]\n",
    "    for i in range(len(path)-1):\n",
    "        if graph.has_edge(path[i], path[i+1]):\n",
    "            final_path.append(path[i+1])\n",
    "        else:\n",
    "            final_path.pop()\n",
    "            final_path.extend(nx.shortest_path(graph, path[i], path[i+1], 'weight'))\n",
    "    last_shortest_path = nx.shortest_path(graph, final_path[-1], start_idx, 'weight')\n",
    "    final_path.pop()\n",
    "    final_path.extend(last_shortest_path)\n",
    "    return final_path, drop_offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = read_file('test_inputs/1_50.in')\n",
    "data = read_file('inputs/79_200.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "mst_solve(lst_loc, lst_house, start_loc, adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch-and-bound using the algorithm in the textbook (NOT WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DEC = 5  # number of decimal numbers for rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "\n",
    "# list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, \n",
    "def add_weights2(g, lower, upper):\n",
    "    \"\"\"Update the weight of each edge to be a random weight within the bounds.\"\"\"\n",
    "    for edge, data in g.edges.items():\n",
    "        w = rd.uniform(lower, upper)\n",
    "        data['weight'] = round(w, NUM_DEC)\n",
    "        \n",
    "def print_edge_weights(g, n=5):\n",
    "    for edge, data in g.edges.items():\n",
    "        if n <= 0:\n",
    "            break\n",
    "        n-=1\n",
    "        print(edge, data)\n",
    "        \n",
    "def is_complete_graph(g):\n",
    "    n = len(g.nodes)\n",
    "    return (n * (n-1) / 2) == len(g.edges())\n",
    "\n",
    "def convert_to_complete_graph(g, starting_car_location, list_of_homes, list_of_locations):\n",
    "    \"\"\"return a complete graph with homes and start loc.\"\"\"\n",
    "    rs = nx.floyd_warshall(g, weight='weight')\n",
    "    result_g = nx.Graph()\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    subgraph_idx = list(set([start_idx] + homes_idx)) # incase starting position is home\n",
    "    \n",
    "    subgraph = g.subgraph(subgraph_idx)\n",
    "    subgraph = subgraph.copy()\n",
    "    for i in range(len(subgraph_idx)):\n",
    "        for j in range(i+1, len(subgraph_idx)):\n",
    "            v0 = subgraph_idx[i]\n",
    "            v1 = subgraph_idx[j]\n",
    "            if not subgraph.has_edge(v0, v1):\n",
    "                subgraph.add_edge(v0, v1, weight = rs[v0][v1])\n",
    "    return subgraph\n",
    "\n",
    "def lowerbound1(g, V, S, a, b):\n",
    "#     print(\"lowerbound1: S(current path) = \", S)\n",
    "    V_set = set(V)\n",
    "    S_set = set(S)\n",
    "    V_minus_S = V_set.difference(S_set)\n",
    "    \n",
    "    cur_min_weight_a = float('inf')\n",
    "    cur_min_weight_b = float('inf')\n",
    "    \n",
    "     # the lighest edge from node to V - S\n",
    "    def find_min_weight(node):\n",
    "        # COMMENT BELOW BECAUSE WE ARE DEALING WITH COMPLETE GRAPH node always has neighbors\n",
    "#         node_nb_set = set(g.neighbors(node))\n",
    "#         node_nb_intersect_V_minus_S = node_nb_set.intersection(V_minus_S)\n",
    "#         cur_min_weight_node =  float('inf')\n",
    "# #         print(\"for node\", node, \"its neighbors\", node_nb_intersect_V_minus_S)\n",
    "#         for node_nb_V_minus_S in node_nb_intersect_V_minus_S:\n",
    "#             cur_min_weight_node = min(cur_min_weight_node,  g.edges[(node, node_nb_V_minus_S)]['weight'])\n",
    "#         return cur_min_weight_node\n",
    "    # *************************************************************\n",
    "        cur_min_weight_node =  float('inf')\n",
    "#         print(\"for node\", node, \"its neighbors\", node_nb_intersect_V_minus_S)\n",
    "        for nb in V_minus_S:\n",
    "            cur_min_weight_node = min(cur_min_weight_node,  g.edges[(node, nb)]['weight'])\n",
    "        return cur_min_weight_node\n",
    "\n",
    " \n",
    "    # the lighest edge from a to V - S\n",
    "    cur_min_weight_a = find_min_weight(a)\n",
    "    \n",
    "    # the lighest edge from b to V - S\n",
    "    cur_min_weight_b = find_min_weight(b)\n",
    "    \n",
    "    # find the sum of weights of MST \n",
    "    V_minus_S_subgraph = g.subgraph(list(V_minus_S))\n",
    "    \n",
    "    mst = nx.minimum_spanning_tree(V_minus_S_subgraph)\n",
    "    sum_weight_mst = sum([data['weight'] for edge, data in mst.edges.items()])\n",
    "    \n",
    "    assert cur_min_weight_a != float('inf') and cur_min_weight_b != float('inf')\n",
    "    return cur_min_weight_a + cur_min_weight_b + sum_weight_mst\n",
    "\n",
    "def branch_and_bound(g, starting_vertex, lower_bound):\n",
    "    active_subproblems = PriorityQueue()\n",
    "#     active_subproblems = []\n",
    "#     active_subproblems.append((starting_vertex, [starting_vertex], starting_vertex))\n",
    "    active_subproblems.put((lower_bound(g, g.nodes(), [starting_vertex], starting_vertex, starting_vertex), (starting_vertex, [starting_vertex], starting_vertex)))\n",
    "    best_so_far = float('inf')\n",
    "    best_path = []\n",
    "    while active_subproblems.qsize() > 0:\n",
    "#     while len(active_subproblems) > 0:\n",
    "        # choose\n",
    "        active_sub = active_subproblems.get()[1]\n",
    "#         active_sub = active_subproblems.pop()\n",
    "#         print(\"active_sub=\", active_sub)\n",
    "        # expand\n",
    "        V_set = set(g.nodes)\n",
    "        S_set = set(tuple(active_sub[1]))\n",
    "        V_minus_S = V_set.difference(S_set)\n",
    "        \n",
    "        for x in V_minus_S:\n",
    "            path = active_sub[1]+[x]\n",
    "            P = (active_sub[0], path , x)\n",
    "            # complete sol\n",
    "            total_w = 0\n",
    "            \n",
    "            \n",
    "            if len(path) == len(g.nodes):\n",
    "                for i in range(len(path)-1):\n",
    "                    total_w += g.edges[(path[i], path[i+1])]['weight']\n",
    "                if total_w < best_so_far:\n",
    "                    best_so_far = total_w\n",
    "                    best_path = path\n",
    "        \n",
    "           \n",
    "            # if lowerbound < bestsofar add Pi to S \n",
    "            else:\n",
    "                cur_lower_bound = lower_bound(g, g.nodes, path, active_sub[0], x)\n",
    "                if cur_lower_bound < best_so_far:\n",
    "                    active_subproblems.put((cur_lower_bound, P))\n",
    "#                     active_subproblems.append(P)\n",
    "                    \n",
    "                #(g, V, S, a, b): \n",
    "    return best_so_far, best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "G1 = nx.complete_graph(10)\n",
    "add_weights2(G1, 1, 100000000)\n",
    "nx.draw(G1, node_color='yellow', with_labels=True)\n",
    "\n",
    "# print_edge_weights(G1, len(G1.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branch-and-bound using permutation (brute force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_complete_graph(g, starting_car_location, list_of_homes, list_of_locations):\n",
    "    \"\"\"return a complete graph with homes and start loc.\"\"\"\n",
    "    rs = nx.floyd_warshall(g, weight='weight')\n",
    "    result_g = nx.Graph()\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    subgraph_idx = list(set([start_idx] + homes_idx)) # incase starting position is home\n",
    "    \n",
    "    subgraph = g.subgraph(subgraph_idx)\n",
    "    subgraph = subgraph.copy()\n",
    "    for i in range(len(subgraph_idx)):\n",
    "        for j in range(i+1, len(subgraph_idx)):\n",
    "            v0 = subgraph_idx[i]\n",
    "            v1 = subgraph_idx[j]\n",
    "            if not subgraph.has_edge(v0, v1):\n",
    "                subgraph.add_edge(v0, v1, weight = rs[v0][v1])\n",
    "    return subgraph\n",
    "\n",
    "def get_cost_of_path(g, path):\n",
    "    total = 0\n",
    "    for i in range(len(path)-1):\n",
    "        total += g.edges[(path[i], path[i+1])]['weight']\n",
    "    return total\n",
    "\n",
    "def all_walk_homes(start_idx, homes_idx):\n",
    "    car_path = [start_idx]\n",
    "    drop_off_locations = {start_idx: homes_idx}\n",
    "    return car_path, drop_off_locations\n",
    "\n",
    "def perm_shortest_cycle(g, start_idx, homes_idx, max_len = 10):\n",
    "    #g is [start, h1, h2, h3]\n",
    "    #append start_idx to the first and last place if home is not start loc\n",
    "    # if start is home, only append last\n",
    "    \n",
    "    g_no_start = list(g.nodes)\n",
    "    g_no_start.remove(start_idx)\n",
    "    perm = permutations(g_no_start) # without the start_idx\n",
    "    \n",
    "    # stop if we think it takes too long to run this(permutation)\n",
    "    if len(g_no_start) > max_len:\n",
    "        return None\n",
    "    print(\"bb_solve\")\n",
    "    cur_min = float(\"inf\")\n",
    "    cur_min_path = []\n",
    "    \n",
    "    for p in perm:\n",
    "        p = list(p)\n",
    "        p.insert(0, start_idx)\n",
    "        p.append(start_idx)\n",
    "        cur_cost = get_cost_of_path(g, p)\n",
    "\n",
    "        if cur_cost < cur_min:\n",
    "            cur_min = cur_cost\n",
    "            cur_min_path = p\n",
    "    return cur_min_path\n",
    "\n",
    "def reconstruct_cycle_from_complete_homes_start_graph(original_g, cycle, start_idx, homes_idx):\n",
    "    car_path = []\n",
    "    drop_off_locations = {}\n",
    "    \n",
    "    cur_idx = cycle.pop(0)\n",
    "    if cur_idx in homes_idx:\n",
    "        drop_off_locations[cur_idx] = [cur_idx]\n",
    "    while cycle:\n",
    "        next_idx = cycle.pop(0)\n",
    "        s_path = nx.shortest_path(original_g, cur_idx, next_idx, weight='weight')\n",
    "        \n",
    "        if len(cycle) != 0: #don't drop off when back to start\n",
    "            drop_off_locations[next_idx] = [next_idx]\n",
    "        s_path.pop()\n",
    "        car_path.extend(s_path)\n",
    "        cur_idx = next_idx\n",
    "\n",
    "    car_path.extend(nx.shortest_path(original_g, cur_idx, start_idx, weight='weight'))\n",
    "    print(car_path)\n",
    "    print(drop_off_locations)\n",
    "    return car_path, drop_off_locations\n",
    "    \n",
    "def branch_and_bound_perm(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    PERM_LEN = 10\n",
    "    \n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    g, msg1 = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "\n",
    "    check_len = 0\n",
    "    if start_idx in homes_idx:\n",
    "        check_len = len(homes_idx) - 1\n",
    "    else:\n",
    "        check_len = len(homes_idx)\n",
    "        \n",
    "    if check_len > PERM_LEN:\n",
    "        return all_walk_homes(start_idx, homes_idx)\n",
    "        \n",
    "    car_path = []\n",
    "    drop_off_locations = {}\n",
    "    \n",
    "    complete_g = convert_to_complete_graph(g, starting_car_location, list_of_homes, list_of_locations)\n",
    "    \n",
    "    shortest_homes_cycle = perm_shortest_cycle(complete_g, start_idx, homes_idx, PERM_LEN)# check len again\n",
    "    if not shortest_homes_cycle:\n",
    "        return all_walk_homes(start_idx, homes_idx)\n",
    "    else:\n",
    "        return reconstruct_cycle_from_complete_homes_start_graph(g, shortest_homes_cycle, start_idx, homes_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('test_inputs/216_50.in') # 116 216 294 52\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "car_path, drop_off_locations = branch_and_bound_perm(lst_loc, lst_house, start_loc, adj_mat)\n",
    "\n",
    "start_idx = lst_loc.index(start_loc)\n",
    "homes_idx = [lst_loc.index(h) for h in lst_house]\n",
    "g, msg1 = adjacency_matrix_to_graph(adj_mat)\n",
    "nx.draw(g, node_color='yellow', with_labels=True)\n",
    "g, msg1 = adjacency_matrix_to_graph(adj_mat)\n",
    "cost_of_solution(g, car_path, drop_off_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rao drives TAs to some dropoff locations (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('inputs/79_200.in')\n",
    "num_loc, num_house, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix = data_parser(data)\n",
    "graph, msg = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "start_idx = list_of_locations.index(starting_car_location)\n",
    "homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "\n",
    "plt.figure(1)\n",
    "nx.draw(graph, with_labels=True)\n",
    "\n",
    "#first compute the best partition\n",
    "partition = community.best_partition(graph)\n",
    "\n",
    "#drawing\n",
    "plt.figure(2)\n",
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(graph)\n",
    "count = 0.\n",
    "for com in set(partition.values()) :\n",
    "#     print(type(com))\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(graph, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n",
    "print('Number of communities: ', count)\n",
    "\n",
    "nx.draw_networkx_edges(graph, pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_homes(k, graph, homes_idx):\n",
    "    lst = []\n",
    "    for node in graph.nodes():\n",
    "        lst_homes = []\n",
    "        neighbors = list(graph.neighbors(node))\n",
    "        for n in neighbors:\n",
    "            if n in homes_idx:\n",
    "                lst_homes.append(n)\n",
    "        if k == 2:\n",
    "            for n in neighbors:\n",
    "                for nn in graph.neighbors(n):\n",
    "                    if nn in homes_idx:\n",
    "                        lst_homes.append(nn)\n",
    "        if len(lst_homes) > 0:\n",
    "            lst.append((node, lst_homes))\n",
    "    return lst\n",
    "\n",
    "def init_pq(lst, graph, cur_idx):\n",
    "    shortest_paths = nx.shortest_path_length(graph, cur_idx, weight='weight')\n",
    "    pq = PriorityQueue()\n",
    "    for i in lst:\n",
    "        node = i[0]\n",
    "        pq.put((shortest_paths[node], i))\n",
    "    return pq\n",
    "    \n",
    "def k_layers_cluster(k, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix):\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    graph, msg = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    path = []\n",
    "    drop_offs = {}\n",
    "    lst = count_homes(k, graph, homes_idx)\n",
    "    cur_idx = start_idx\n",
    "    while homes_idx:\n",
    "        pq = init_pq(lst, graph, cur_idx)\n",
    "        cost, center_homes = pq.get()\n",
    "        center = center_homes[0]\n",
    "        lst_homes = center_homes[1]\n",
    "        lst_copy = lst_homes.copy()\n",
    "        for h in lst_copy:\n",
    "            if h in homes_idx:\n",
    "                homes_idx.remove(h)\n",
    "            else:\n",
    "                lst_homes.remove(h)\n",
    "        if lst_homes:\n",
    "            shortest_path = nx.shortest_path(graph, cur_idx, center, 'weight')\n",
    "            shortest_path.pop()\n",
    "            path.extend(shortest_path)\n",
    "            drop_offs[center] = lst_homes\n",
    "            cur_idx = center\n",
    "        lst.remove(center_homes)\n",
    "    last_shortest_path = nx.shortest_path(graph, cur_idx, start_idx, 'weight')\n",
    "    path.extend(last_shortest_path)\n",
    "    return path, drop_offs\n",
    "    \n",
    "def nn_cluster_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    return k_layers_cluster(2, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('inputs/79_200.in')\n",
    "num_loc, num_house, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix = data_parser(data)\n",
    "nn_cluster_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_homes(k, graph, homes_idx):\n",
    "    lst = []\n",
    "    for node in graph.nodes():\n",
    "        lst_homes = []\n",
    "        neighbors = list(graph.neighbors(node))\n",
    "        for n in neighbors:\n",
    "            if n in homes_idx:\n",
    "                lst_homes.append(n)\n",
    "        if k == 2:\n",
    "            for n in neighbors:\n",
    "                for nn in graph.neighbors(n):\n",
    "                    if nn in homes_idx:\n",
    "                        lst_homes.append(nn)\n",
    "        if len(lst_homes) > 0:\n",
    "            lst.append((node, lst_homes))\n",
    "    return lst\n",
    "\n",
    "def init_pq(lst, graph, cur_idx):\n",
    "    shortest_paths = nx.shortest_path_length(graph, cur_idx, weight='weight')\n",
    "    pq = PriorityQueue()\n",
    "    for i in lst:\n",
    "        node = i[0]\n",
    "        pq.put((shortest_paths[node], i))\n",
    "    return pq\n",
    "    \n",
    "def k_layers_cluster2(k, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix):\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    graph, msg = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    path = []\n",
    "    drop_offs = {}\n",
    "    lst = count_homes(k, graph, homes_idx)\n",
    "    cur_idx = start_idx\n",
    "    while homes_idx:\n",
    "        pq = init_pq(lst, graph, cur_idx)\n",
    "        cost, center_homes = pq.get()\n",
    "        center = center_homes[0]\n",
    "        lst_homes = center_homes[1]\n",
    "        lst_copy = lst_homes.copy()\n",
    "        for h in lst_copy:\n",
    "            if h in homes_idx:\n",
    "                homes_idx.remove(h)\n",
    "            else:\n",
    "                lst_homes.remove(h)\n",
    "        if lst_homes:\n",
    "            if len(lst_homes) == 1:\n",
    "                center = lst_homes[0]\n",
    "            shortest_path = nx.shortest_path(graph, cur_idx, center, 'weight')\n",
    "            shortest_path.pop()\n",
    "            path.extend(shortest_path)\n",
    "            if center in drop_offs:\n",
    "                drop_offs[center] += lst_homes\n",
    "            else:\n",
    "                drop_offs[center] = lst_homes\n",
    "            cur_idx = center\n",
    "        lst.remove(center_homes)\n",
    "    last_shortest_path = nx.shortest_path(graph, cur_idx, start_idx, 'weight')\n",
    "    path.extend(last_shortest_path)\n",
    "    return path, drop_offs\n",
    "    \n",
    "def nn_cluster_solve2(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    return k_layers_cluster2(1, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('inputs/79_200.in')\n",
    "num_loc, num_house, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix = data_parser(data)\n",
    "G, msg = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "car_path, dropoffs = nn_cluster_solve2(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix)\n",
    "print(car_path)\n",
    "print(dropoffs)\n",
    "print(cost_of_solution_no_print(G, car_path, dropoffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_clustering_solver(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    # Count adjacent homes for each vertice and add them to the PQ\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    g, msg1 = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    PQ = PriorityQueue()\n",
    "    car_path = []\n",
    "    drop_off_locations = {}\n",
    "    \n",
    "    # initilize PQ\n",
    "    for v in g.nodes():\n",
    "        homes = []\n",
    "        for nb in g.neighbors(v):\n",
    "            if nb in homes_idx:\n",
    "                homes.append(nb)\n",
    "        PQ.put((len(homes), (v, homes)))\n",
    "    cur_idx = start_idx\n",
    "    while homes_idx:\n",
    "        (dropoff_loc, dropoff_homes) = PQ.get()[1]\n",
    "        dropoff_copy = dropoff_homes.copy()\n",
    "        for h in dropoff_copy:\n",
    "            if h in homes_idx:\n",
    "                homes_idx.remove(h)\n",
    "            else:\n",
    "                dropoff_homes.remove(h)\n",
    "        if dropoff_homes:\n",
    "            s_path = nx.shortest_path(g, cur_idx, dropoff_loc, weight='weight')\n",
    "            cur_idx = dropoff_loc\n",
    "            s_path.pop()\n",
    "            car_path.extend(s_path)\n",
    "            drop_off_locations[dropoff_loc] = dropoff_homes\n",
    "    \n",
    "    car_path.extend(nx.shortest_path(g, cur_idx, start_idx, weight='weight'))\n",
    "    return car_path, drop_off_locations   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('test_inputs/27_200.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "car_path, drop_off_locations = greedy_clustering_solver(lst_loc, lst_house, start_loc, adj_mat)\n",
    "\n",
    "g, msg1 = adjacency_matrix_to_graph(adj_mat)\n",
    "print(car_path)\n",
    "print(cost_of_solution(g, car_path, drop_off_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('test_inputs/116_50.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "car_path, drop_off_locations = greedy_clustering_solver(lst_loc, lst_house, start_loc, adj_mat)\n",
    "\n",
    "g, msg1 = adjacency_matrix_to_graph(adj_mat)\n",
    "print(car_path)\n",
    "print(cost_of_solution(g, car_path, drop_off_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_cost(car_path, shortest_paths):\n",
    "    total = 0\n",
    "    for i in range(len(car_path)-1):\n",
    "        total += (shortest_paths[car_path[i]][car_path[i+1]] * 2 / 3) \n",
    "    return total\n",
    "    \n",
    "def inverse(car_path, i, j):\n",
    "    \"\"\"swap anything in between i and j, both indices inclusively\"\"\"\n",
    "    return car_path[:i] + car_path[i:j+1][::-1] + car_path[j+1:]\n",
    "\n",
    "def insert(car_path, i, j):\n",
    "    p = car_path[:]\n",
    "    item = p.pop(j)\n",
    "    p.insert(i, item)\n",
    "    return p\n",
    "\n",
    "def swap(car_path, i, j):\n",
    "    p = car_path[:]\n",
    "    p[i], p[j] = p[j], p[i]\n",
    "    return p\n",
    "\n",
    "def get_valid_dropoffs(car_path, homes_idx):\n",
    "    drop_off_locations = {}\n",
    "    for v in car_path:\n",
    "        if v in homes_idx:\n",
    "            drop_off_locations[v] = [v]\n",
    "    return drop_off_locations\n",
    "\n",
    "def get_local_best_neighbor(car_path, shortest_paths, i ,j):\n",
    "    \"\"\"Minimum of three modified paths, original one not included\"\"\"\n",
    "    p1 = inverse(car_path, i, j)\n",
    "    p2 = insert(car_path, i, j)\n",
    "    p3 = swap(car_path, i, j)\n",
    "    cost_dict = {}\n",
    "    cost_dict[\"p1\"] = get_shortest_cost(p1, shortest_paths)\n",
    "    cost_dict[\"p2\"] = get_shortest_cost(p2, shortest_paths)\n",
    "    cost_dict[\"p3\"] = get_shortest_cost(p3, shortest_paths)\n",
    "    minKey = min(cost_dict, key=cost_dict.get)\n",
    "    if minKey == \"p1\":\n",
    "        return p1, cost_dict[\"p1\"]\n",
    "    elif minKey == \"p2\":\n",
    "        return p2, cost_dict[\"p2\"]\n",
    "    else:\n",
    "        return p3, cost_dict[\"p3\"]\n",
    "\n",
    "def reconstruct_full_cycle_from_incomplete_cycle(original_g, cycle, start_idx, homes_idx):\n",
    "    \"\"\"fill in the vertices betwee each pair of vertices in cycle based on the original graph\"\"\"\n",
    "    car_path = []\n",
    "    drop_off_locations = {}\n",
    "    \n",
    "    cur_idx = cycle.pop(0)\n",
    "    if cur_idx in homes_idx:\n",
    "        drop_off_locations[cur_idx] = [cur_idx]\n",
    "    while cycle:\n",
    "        next_idx = cycle.pop(0)\n",
    "        s_path = nx.shortest_path(original_g, cur_idx, next_idx, weight='weight')\n",
    "        \n",
    "        if len(cycle) != 0: #don't drop off when back to start\n",
    "            drop_off_locations[next_idx] = [next_idx]\n",
    "        s_path.pop()\n",
    "        car_path.extend(s_path)\n",
    "        cur_idx = next_idx\n",
    "\n",
    "    car_path.extend(nx.shortest_path(original_g, cur_idx, start_idx, weight='weight'))\n",
    "    return car_path, drop_off_locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_MAX = 120\n",
    "L_MAX = 60\n",
    "INIT_TEMP = 18\n",
    "ITER_NUM = 1000\n",
    "INIT_PROB = 0.5\n",
    "\n",
    "def init_temp_list(car_path, shortest_paths, length):\n",
    "    L = PriorityQueue()\n",
    "    i = 0\n",
    "    while i < length:\n",
    "        neighbor, costy = rand_gen_neighbor(car_path, shortest_paths)\n",
    "        costx = get_shortest_cost(car_path, shortest_paths)\n",
    "        if costy < costx:\n",
    "            car_path = neighbor\n",
    "        else:\n",
    "            t = -abs(costy - costx) / math.log(INIT_PROB)\n",
    "            L.put(-t)\n",
    "            i = i + 1\n",
    "    return L\n",
    "\n",
    "def gen_rand_idx(x, y):\n",
    "    while True:\n",
    "        a = rd.randint(x, y)\n",
    "        b = rd.randint(x, y)\n",
    "        if abs(a-b) >= 2:\n",
    "            if a < b:\n",
    "                return a, b\n",
    "            else:\n",
    "                return b, a\n",
    "            \n",
    "def rand_gen_neighbor(car_path, shortest_paths):\n",
    "    i, j = gen_rand_idx(1, len(car_path)-2)\n",
    "    return get_local_best_neighbor(car_path, shortest_paths, i, j)\n",
    "\n",
    "def acceptance_probability(delta, t_max):\n",
    "    try:\n",
    "        return math.exp(-delta / t_max)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    except OverflowError:\n",
    "        return 0\n",
    "\n",
    "def new_temp(t, delta, r):\n",
    "    return (t - delta) / math.log(r)\n",
    "\n",
    "def local_search(car_path, shortest_paths):\n",
    "    L = init_temp_list(car_path, shortest_paths, L_MAX)\n",
    "    k = 0\n",
    "    while k < L_MAX - 1:\n",
    "        t_max = -L.get(block=False)\n",
    "        k = k + 1\n",
    "        t = 0\n",
    "        c = 0\n",
    "        m = 0\n",
    "        while m < ITER_NUM:\n",
    "            m = m + 1\n",
    "            neighbor, costy = rand_gen_neighbor(car_path, shortest_paths)\n",
    "            costx = get_shortest_cost(car_path, shortest_paths)\n",
    "            if costy < costx:\n",
    "                car_path = neighbor\n",
    "            else:\n",
    "                delta = costy - costx\n",
    "                p = acceptance_probability(delta, t_max)\n",
    "                r = rd.random()\n",
    "                if r < p:\n",
    "                    t = new_temp(t, delta, r)\n",
    "                    c = c + 1\n",
    "        if c != 0:\n",
    "            L.get(block=False)\n",
    "            L.put(-t/c)\n",
    "    return car_path\n",
    "    \n",
    "def local_search_solver(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, input_file, params=[]):\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    graph, msg = student_utils.adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    \n",
    "    nn_output_directory = 'nearest_neighbor_algo/outputs'\n",
    "    nn_output_file = utils.input_to_output(input_file, nn_output_directory)\n",
    "    nn_output_data = utils.read_file(nn_output_file)\n",
    "    car_cycle = nn_output_data[0]\n",
    "    car_cycle_idx = student_utils.convert_locations_to_indices(car_cycle, list_of_locations)\n",
    "\n",
    "    shortest_paths = nx.floyd_warshall(graph, weight='weight')\n",
    "    new_car_cycle_idx = local_search(car_cycle_idx, shortest_paths)\n",
    "\n",
    "    #final_path\n",
    "    final_cycle = []\n",
    "    for i in range(len(new_car_cycle_idx)-1):\n",
    "        shortest_path = nx.shortest_path(graph, new_car_cycle_idx[i], new_car_cycle_idx[i+1], weight='weight')\n",
    "        shortest_path.pop()\n",
    "        final_cycle.extend(shortest_path)\n",
    "    final_cycle.append(new_car_cycle_idx[-1])\n",
    "    dropoffs = get_valid_dropoffs(final_cycle, homes_idx)\n",
    "    return final_cycle, dropoffs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
