{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "from student_utils import *\n",
    "from utils import *\n",
    "import community\n",
    "# from ipynb.fs.full.gen_inputs import add_weights2\n",
    "from queue import PriorityQueue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building outputs from all algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best output for each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_outputs(pickle_dir):\n",
    "    pfiles = get_files_with_extension(pickle_dir, 'p')\n",
    "    dic = {}\n",
    "    meta_dic = {}\n",
    "    for pf in pfiles:\n",
    "        pobj = load_obj(pf)\n",
    "        for item in pobj:\n",
    "            # key=<./path/to/input_file>.in, value=(<./path/to/output_file.out>, cost)\n",
    "            input_file = item[0]\n",
    "            output_file = item[1]\n",
    "            cost = item[2][0]\n",
    "            if input_file in dic:\n",
    "                dic[input_file].append((output_file, cost))\n",
    "            else:\n",
    "                dic[input_file] = [(output_file, cost)]\n",
    "    if not os.path.isdir('final/outputs'):\n",
    "        os.mkdir('final')\n",
    "        os.mkdir('final/outputs')\n",
    "    for lst in dic.values():\n",
    "        best_output, best_cost = min(lst, key=lambda x: x[1])\n",
    "        os.system('cp ' + best_output + ' final/outputs/')\n",
    "        meta_dic[best_output] = best_cost\n",
    "    save_obj(meta_dic, 'final/meta.p')\n",
    "    write_data_to_file('final/meta.txt', meta_dic.items(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_outputs('pickle_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric TSP Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: A polynomial-time Algo with cost <= 2*optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take the MST of G.\n",
    "2. Do a DPS on MST to get PT(pseudotour).\n",
    "3. Go from PT to T* (Take each vertex only the first time it appears in PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.complete_graph(10)\n",
    "add_weights2(G1, 1, 10)\n",
    "print(list(G1.edges().data()))\n",
    "plt.subplot()\n",
    "nx.draw(G1, node_color='yellow', with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_homes = [0,1,2,3,4]\n",
    "G1_sub = G1.subgraph(ta_homes)\n",
    "print(list(G1_sub.edges().data()))\n",
    "plt.subplot()\n",
    "nx.draw(G1_sub, node_color='yellow', with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT = nx.minimum_spanning_tree(G1_sub)\n",
    "# print(sorted(PT.edges(data=True)))\n",
    "print(PT.edges(data=True))\n",
    "\n",
    "plt.subplot()\n",
    "nx.draw(PT, node_color='yellow', with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement dfs yielding pseudotour\n",
    "list(nx.dfs_edges(PT, source=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rao drives every TA home: this is a TSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    graph1, msg1 = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    path = []\n",
    "    drop_offs = {}\n",
    "    current_idx = start_idx\n",
    "    while homes_idx:\n",
    "        lst_dist = [(h_idx, nx.shortest_path_length(graph1, current_idx, h_idx, 'weight')) for h_idx in homes_idx]\n",
    "        idx, _ = min(lst_dist, key=lambda x: x[1])\n",
    "        shortest_path = nx.shortest_path(graph1, current_idx, idx, 'weight')\n",
    "        shortest_path.pop()\n",
    "        path.extend(shortest_path)\n",
    "        drop_offs[idx] = [idx]\n",
    "        current_idx = idx\n",
    "        homes_idx.remove(idx)\n",
    "    last_shortest_path = nx.shortest_path(graph1, current_idx, start_idx, 'weight')\n",
    "    path.extend(last_shortest_path)\n",
    "    return path, drop_offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('test_inputs/27_50.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "nn_solve(lst_loc, lst_house, start_loc, adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Approximation using MST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the MST is connected then we can perform DFS and construct the path.\n",
    "- If the MST is not connected then we need to connect all homes by finding shortest paths between them.\n",
    "- To get the final path we look at each path in the list and check in the original graph, if there is an edge then we do nothing, but if it does not have an edge then we replace it with the shortest path between those nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_homes(graph, nodes):\n",
    "    newgraph = nx.Graph()\n",
    "    newgraph.add_nodes_from(nodes)\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            w = nx.shortest_path_length(graph, nodes[i], nodes[j], 'weight')\n",
    "            newgraph.add_edge(nodes[i], nodes[j], weight=w)\n",
    "    return newgraph\n",
    "    \n",
    "def mst_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    nodes = homes_idx + [start_idx]\n",
    "    graph, msg = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    newgraph = graph.subgraph(nodes)\n",
    "    if not nx.is_connected(newgraph):\n",
    "        newgraph = connect_homes(graph, nodes)\n",
    "    mst = nx.minimum_spanning_tree(newgraph, 'weight')\n",
    "    dfs = list(nx.dfs_edges(mst, start_idx))\n",
    "    path = [start_idx]\n",
    "    drop_offs = {}\n",
    "    if start_idx in homes_idx:\n",
    "        drop_offs[start_idx] = [start_idx]\n",
    "    current_idx = -1\n",
    "    while dfs:\n",
    "        edge = dfs.pop(0)\n",
    "        current_idx = edge[1]\n",
    "        if current_idx not in path:\n",
    "            path.append(current_idx)\n",
    "            drop_offs[current_idx] = [current_idx]\n",
    "    final_path = [path[0]]\n",
    "    for i in range(len(path)-1):\n",
    "        if graph.has_edge(path[i], path[i+1]):\n",
    "            final_path.append(path[i+1])\n",
    "        else:\n",
    "            final_path.pop()\n",
    "            final_path.extend(nx.shortest_path(graph, path[i], path[i+1], 'weight'))\n",
    "    last_shortest_path = nx.shortest_path(graph, final_path[-1], start_idx, 'weight')\n",
    "    final_path.pop()\n",
    "    final_path.extend(last_shortest_path)\n",
    "    return final_path, drop_offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = read_file('test_inputs/1_50.in')\n",
    "data = read_file('inputs/79_200.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "mst_solve(lst_loc, lst_house, start_loc, adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5-Approximation using Christofides Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch-and-bound using the algorithm in the textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DEC = 5  # number of decimal numbers for rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "\n",
    "# list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, \n",
    "def add_weights2(g, lower, upper):\n",
    "    \"\"\"Update the weight of each edge to be a random weight within the bounds.\"\"\"\n",
    "    for edge, data in g.edges.items():\n",
    "        w = rd.uniform(lower, upper)\n",
    "        data['weight'] = round(w, NUM_DEC)\n",
    "        \n",
    "def print_edge_weights(g, n=5):\n",
    "    for edge, data in g.edges.items():\n",
    "        if n <= 0:\n",
    "            break\n",
    "        n-=1\n",
    "        print(edge, data)\n",
    "        \n",
    "def is_complete_graph(g):\n",
    "    n = len(g.nodes())\n",
    "    return (n * (n-1) / 2) == len(g.edges())\n",
    "\n",
    "def convert_to_complete_graph(g, starting_car_location, list_of_homes, list_of_locations):\n",
    "    rs = nx.floyd_warshall(g, weight='weight')\n",
    "    result_g = nx.Graph()\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    subgraph_idx = [start_idx] + homes_idx\n",
    "    subgraph = g.subgraph(subgraph_idx)\n",
    "    subgraph = subgraph.copy()\n",
    "    for i in range(len(subgraph_idx)):\n",
    "        for j in range(i+1, len(subgraph_idx)):\n",
    "            v0 = subgraph_idx[i]\n",
    "            v1 = subgraph_idx[j]\n",
    "            if not subgraph.has_edge(v0, v1):\n",
    "                subgraph.add_edge(v0, v1, weight = rs[v0][v1])\n",
    "#                 subgraph.edges[(i, j)]['weight'] = rs[i][j]\n",
    "    return subgraph\n",
    "\n",
    "def lowerbound1(g, V, S, a, b):\n",
    "#     print(\"lowerbound1: S(current path) = \", S)\n",
    "    V_set = set(V)\n",
    "    S_set = set(S)\n",
    "    V_minus_S = V_set.difference(S_set)\n",
    "    \n",
    "    cur_min_weight_a = float('inf')\n",
    "    cur_min_weight_b = float('inf')\n",
    "    \n",
    "     # the lighest edge from node to V - S\n",
    "    def find_min_weight(node):\n",
    "        # COMMENT BELOW BECAUSE WE ARE DEALING WITH COMPLETE GRAPH node always has neighbors\n",
    "#         node_nb_set = set(g.neighbors(node))\n",
    "#         node_nb_intersect_V_minus_S = node_nb_set.intersection(V_minus_S)\n",
    "#         cur_min_weight_node =  float('inf')\n",
    "# #         print(\"for node\", node, \"its neighbors\", node_nb_intersect_V_minus_S)\n",
    "#         for node_nb_V_minus_S in node_nb_intersect_V_minus_S:\n",
    "#             cur_min_weight_node = min(cur_min_weight_node,  g.edges[(node, node_nb_V_minus_S)]['weight'])\n",
    "#         return cur_min_weight_node\n",
    "    # *************************************************************\n",
    "        cur_min_weight_node =  float('inf')\n",
    "#         print(\"for node\", node, \"its neighbors\", node_nb_intersect_V_minus_S)\n",
    "        for nb in V_minus_S:\n",
    "            cur_min_weight_node = min(cur_min_weight_node,  g.edges[(node, nb)]['weight'])\n",
    "        return cur_min_weight_node\n",
    "\n",
    " \n",
    "    # the lighest edge from a to V - S\n",
    "    cur_min_weight_a = find_min_weight(a)\n",
    "    \n",
    "    # the lighest edge from b to V - S\n",
    "    cur_min_weight_b = find_min_weight(b)\n",
    "    \n",
    "    # find the sum of weights of MST \n",
    "    V_minus_S_subgraph = g.subgraph(list(V_minus_S))\n",
    "    \n",
    "    mst = nx.minimum_spanning_tree(V_minus_S_subgraph)\n",
    "    sum_weight_mst = sum([data['weight'] for edge, data in mst.edges.items()])\n",
    "    \n",
    "    assert cur_min_weight_a != float('inf') and cur_min_weight_b != float('inf')\n",
    "    return cur_min_weight_a + cur_min_weight_b + sum_weight_mst\n",
    "\n",
    "def branch_and_bound(g, starting_vertex, lower_bound):\n",
    "#     active_subproblems = PriorityQueue()\n",
    "    active_subproblems = []\n",
    "    active_subproblems.append((starting_vertex, [starting_vertex], starting_vertex))\n",
    "#     active_subproblems.put((lower_bound(g, g.nodes(), [starting_vertex], starting_vertex, starting_vertex), (starting_vertex, [starting_vertex], starting_vertex)))\n",
    "    best_so_far = float('inf')\n",
    "    best_path = []\n",
    "#     while active_subproblems.qsize() > 0:\n",
    "    while len(active_subproblems) > 0:\n",
    "        # choose\n",
    "#         active_sub = active_subproblems.get()[1]\n",
    "        active_sub = active_subproblems.pop()\n",
    "#         print(\"active_sub=\", active_sub)\n",
    "        # expand\n",
    "        V_set = set(g.nodes())\n",
    "        S_set = set(tuple(active_sub[1]))\n",
    "        V_minus_S = V_set.difference(S_set)\n",
    "        \n",
    "        for x in V_minus_S:\n",
    "            path = active_sub[1]+[x]\n",
    "            P = (active_sub[0], path , x)\n",
    "#             print(\"P = \", P)\n",
    "            # complete sol\n",
    "            total_w = 0\n",
    "            \n",
    "            \n",
    "            if len(path) == len(g.nodes()):\n",
    "                for i in range(len(path)-1):\n",
    "#                     print(\"***********\")\n",
    "#                     print(path[i], path[i+1])\n",
    "                    total_w += g.edges[(path[i], path[i+1])]['weight']\n",
    "#                 print(\"considering \", total_w, path)\n",
    "                if total_w < best_so_far:\n",
    "                    best_so_far = total_w\n",
    "                    best_path = path\n",
    "        \n",
    "           \n",
    "            # if lowerbound < bestsofar add Pi to S \n",
    "            else:\n",
    "                cur_lower_bound = lower_bound(g, g.nodes(), path, active_sub[0], x)\n",
    "                if cur_lower_bound < best_so_far:\n",
    "#                     active_subproblems.put((cur_lower_bound, P))\n",
    "                    active_subproblems.append(P)\n",
    "                    \n",
    "                #(g, V, S, a, b): \n",
    "    return best_so_far, best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "G1 = nx.complete_graph(11)\n",
    "add_weights2(G1, 1, 100000000)\n",
    "nx.draw(G1, node_color='yellow', with_labels=True)\n",
    "\n",
    "print_edge_weights(G1, len(G1.edges()))\n",
    "\n",
    "# converted_g=convert_to_complete_graph(G1, 0, [1, 2, 3], [0,1,2,3])  \n",
    "# print(is_complete_graph(converted_g))        \n",
    "# nx.draw(converted_g, node_color='yellow', with_labels=True)\n",
    "\n",
    "# print(lowerbound(G1, G1.nodes(), [0], 0, 0))\n",
    "# branch_and_bound(G1, 0, lowerbound1)\n",
    "# q = PriorityQueue()\n",
    "# q.put((1, \"a\"))\n",
    "# q.put((-1, \"b\"))\n",
    "# # print(q.get())\n",
    "# # print(q.get())\n",
    "# print(q.qsize())\n",
    "# print(set(tuple([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_and_bound(G1, 0, lowerbound1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def get_cost_of_path(g, path):\n",
    "    total = 0\n",
    "    for i in range(len(path)-1):\n",
    "        total += g.edges[(path[i], path[i+1])]['weight']\n",
    "    return total\n",
    "        \n",
    "perm = permutations(G1.nodes())\n",
    "all_cost = []\n",
    "# print(list(perm))\n",
    "cur_min = float(\"inf\")\n",
    "cur_min_path = []\n",
    "for p in perm:\n",
    "    p = list(p)\n",
    "#     p.append(0)\n",
    "    if p[0] == 0:\n",
    "        cur_cost = get_cost_of_path(G1, p)\n",
    "        all_cost.append(cur_cost)\n",
    "#         print(cur_cost, p)\n",
    "\n",
    "        if cur_cost < cur_min:\n",
    "            cur_min = cur_cost\n",
    "            cur_min_path = p\n",
    "print(cur_min)\n",
    "print(cur_min_path)\n",
    "# print(all_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch-and-bound using another lower-bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rao drives TAs to some dropoff locations (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('inputs/79_200.in')\n",
    "num_loc, num_house, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix = data_parser(data)\n",
    "graph, msg = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "start_idx = list_of_locations.index(starting_car_location)\n",
    "homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "\n",
    "plt.figure(1)\n",
    "nx.draw(graph, with_labels=True)\n",
    "\n",
    "#first compute the best partition\n",
    "partition = community.best_partition(graph)\n",
    "\n",
    "#drawing\n",
    "plt.figure(2)\n",
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(graph)\n",
    "count = 0.\n",
    "for com in set(partition.values()) :\n",
    "#     print(type(com))\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(graph, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n",
    "print('Number of communities: ', count)\n",
    "\n",
    "nx.draw_networkx_edges(graph, pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_homes(k, graph, homes_idx):\n",
    "    lst = []\n",
    "    for node in graph.nodes():\n",
    "        lst_homes = []\n",
    "        neighbors = list(graph.neighbors(node))\n",
    "        for n in neighbors:\n",
    "            if n in homes_idx:\n",
    "                lst_homes.append(n)\n",
    "        if k == 2:\n",
    "            for n in neighbors:\n",
    "                for nn in graph.neighbors(n):\n",
    "                    if nn in homes_idx:\n",
    "                        lst_homes.append(nn)\n",
    "        if len(lst_homes) > 0:\n",
    "            lst.append((node, lst_homes))\n",
    "    return lst\n",
    "\n",
    "def init_pq(lst, graph, cur_idx):\n",
    "    shortest_paths = nx.shortest_path_length(graph, cur_idx, weight='weight')\n",
    "    pq = PriorityQueue()\n",
    "    for i in lst:\n",
    "        node = i[0]\n",
    "        pq.put((shortest_paths[node], i))\n",
    "    return pq\n",
    "    \n",
    "def k_layers_cluster(k, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix):\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    graph, msg = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    path = []\n",
    "    drop_offs = {}\n",
    "    lst = count_homes(k, graph, homes_idx)\n",
    "    cur_idx = start_idx\n",
    "    while homes_idx:\n",
    "        pq = init_pq(lst, graph, cur_idx)\n",
    "        cost, center_homes = pq.get()\n",
    "        center = center_homes[0]\n",
    "        lst_homes = center_homes[1]\n",
    "        lst_copy = lst_homes.copy()\n",
    "        for h in lst_copy:\n",
    "            if h in homes_idx:\n",
    "                homes_idx.remove(h)\n",
    "            else:\n",
    "                lst_homes.remove(h)\n",
    "        if lst_homes:\n",
    "            shortest_path = nx.shortest_path(graph, cur_idx, center, 'weight')\n",
    "            shortest_path.pop()\n",
    "            path.extend(shortest_path)\n",
    "            drop_offs[center] = lst_homes\n",
    "            cur_idx = center\n",
    "        lst.remove(center_homes)\n",
    "    last_shortest_path = nx.shortest_path(graph, cur_idx, start_idx, 'weight')\n",
    "    path.extend(last_shortest_path)\n",
    "    return path, drop_offs\n",
    "    \n",
    "def nn_cluster_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    return k_layers_cluster(2, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('inputs/79_200.in')\n",
    "num_loc, num_house, list_of_locations, list_of_homes, starting_car_location, adjacency_matrix = data_parser(data)\n",
    "nn_cluster_solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_clustering(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    # Count adjacent homes for each vertice and add them to the PQ\n",
    "    start_idx = list_of_locations.index(starting_car_location)\n",
    "    homes_idx = [list_of_locations.index(h) for h in list_of_homes]\n",
    "    g, msg1 = adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    PQ = PriorityQueue()\n",
    "    car_path = []\n",
    "    drop_off_locations = {}\n",
    "    \n",
    "    # initilize PQ\n",
    "    for v in g.nodes():\n",
    "        homes = []\n",
    "        for nb in g.neighbors(v):\n",
    "            if nb in homes_idx:\n",
    "                homes.append(nb)\n",
    "        PQ.put((len(homes), (v, homes)))\n",
    "        \n",
    "#     (prev_dropoff_loc, dropoff_homes) = PQ.get()[1]\n",
    "#     dropoff_copy = dropoff_homes.copy()\n",
    "#     for h in dropoff_copy:\n",
    "#         if h in homes_idx:\n",
    "#             homes_idx.remove(h)\n",
    "#         else:\n",
    "#             dropoff_homes.remove(h)\n",
    "#     if dropoff_homes:\n",
    "#         car_path.extend(nx.shortest_path(g, start_idx, prev_dropoff_loc, weight='weight'))\n",
    "#         drop_off_locations[prev_dropoff_loc] = dropoff_homes\n",
    "    \n",
    "    \n",
    "    cur_idx = start_idx\n",
    "    while homes_idx:\n",
    "        (dropoff_loc, dropoff_homes) = PQ.get()[1]\n",
    "        dropoff_copy = dropoff_homes.copy()\n",
    "        for h in dropoff_copy:\n",
    "            if h in homes_idx:\n",
    "                homes_idx.remove(h)\n",
    "            else:\n",
    "                dropoff_homes.remove(h)\n",
    "        if dropoff_homes:\n",
    "            s_path = nx.shortest_path(g, cur_idx, dropoff_loc, weight='weight')\n",
    "            cur_idx = dropoff_loc\n",
    "            s_path.pop()\n",
    "            car_path.extend(s_path)\n",
    "            drop_off_locations[dropoff_loc] = dropoff_homes\n",
    "    \n",
    "    car_path.extend(nx.shortest_path(g, cur_idx, start_idx, weight='weight'))\n",
    "    return car_path, drop_off_locations   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('test_inputs/27_200.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "car_path, drop_off_locations = greedy_clustering(lst_loc, lst_house, start_loc, adj_mat)\n",
    "\n",
    "g, msg1 = adjacency_matrix_to_graph(adj_mat)\n",
    "print(car_path)\n",
    "print(cost_of_solution(g, car_path, drop_off_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('test_inputs/116_50.in')\n",
    "num_loc, num_house, lst_loc, lst_house, start_loc, adj_mat = data_parser(data)\n",
    "car_path, drop_off_locations = greedy_clustering(lst_loc, lst_house, start_loc, adj_mat)\n",
    "\n",
    "g, msg1 = adjacency_matrix_to_graph(adj_mat)\n",
    "print(car_path)\n",
    "print(cost_of_solution(g, car_path, drop_off_locations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
